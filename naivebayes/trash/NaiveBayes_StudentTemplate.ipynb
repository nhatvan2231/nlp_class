{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d95443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clickbait_data():\n",
    "    df = pd.read_csv('./clickbait_data.csv')\n",
    "    df, test_df = train_test_split(df, test_size=0.1, random_state=17)\n",
    "    texts = df['headline']\n",
    "    labels = df['clickbait'].values.astype(int)\n",
    "    test_texts = test_df['headline'].values\n",
    "    test_labels = test_df['clickbait'].values.astype(int)\n",
    "    \n",
    "    return texts, labels, test_texts, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa977f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(texts, test_texts):\n",
    "    vectorizer = CountVectorizer(max_features=10000, stop_words='english')\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    \n",
    "    return X, X_test, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fd0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(X, labels, vectorizer):\n",
    "    X_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    \n",
    "    X_df['--label--'] = labels.astype(int)\n",
    "    \n",
    "    # log_prob_class\n",
    "    class_count_ = X_df['--label--'].value_counts()\n",
    "    log_class_count = np.log(class_count_)\n",
    "    log_prob_class = log_class_count - np.log(class_count_.sum())\n",
    "    \n",
    "    # log_prob_token\n",
    "    token_count_per_class = X_df.groupby('--label--').sum().reset_index(level=0, drop=True)\n",
    "    token_count_per_class = token_count_per_class + 1.0\n",
    "    token_per_class = token_count_per_class.sum(1).values.reshape(-1, 1)\n",
    "    \n",
    "    prob_token_count_per_class = np.log(token_count_per_class) - np.log(token_per_class)\n",
    "    \n",
    "    return prob_token_count_per_class, log_prob_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defed45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_doc(doc, vectorizer, prob_token_count_per_class, log_prob_class):\n",
    "    # TODO\n",
    "    # This function input a document ``doc\" and return the prediction ``pred\" (numeric output of 0 or 1)\n",
    "    # An output ``pred\" of 0 means we predict the document ``doc\" as non-clickbait\n",
    "    # An output ``pred\"of 1 means we predict the document ``doc\" as clickbait\n",
    "    \n",
    "    # END TODO\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75359d71",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9789ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels, test_texts, test_labels = load_clickbait_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b23706",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, vectorizer = feature_extraction(texts, test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61aefdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_token_count_per_class, log_prob_class = train_naive_bayes(X, labels, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i, doc in enumerate(test_texts):\n",
    "    preds.append(predict_single_doc(doc, vectorizer, prob_token_count_per_class, log_prob_class))\n",
    "    if i % 500 == 0:\n",
    "        print(\"Done\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dedced",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94b413",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdfc07f",
   "metadata": {},
   "source": [
    "#### Compare your results with the scikit-learn Naive Bayes implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e0bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, labels)\n",
    "print(classification_report(test_labels, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac1cd90",
   "metadata": {},
   "source": [
    "##### Make sure the results from your implementation is the same or similar to the one implemented in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce889ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
